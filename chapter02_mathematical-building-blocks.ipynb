{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsuptYAqNq-I"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7YSiw9PDNq-J",
        "outputId": "10256ee5-2dc3-402e-e602-e05b8d2f57a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras-nlp 0.21.1\n",
            "Uninstalling keras-nlp-0.21.1:\n",
            "  Successfully uninstalled keras-nlp-0.21.1\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.13.1)\n",
            "Requirement already satisfied: keras-hub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from keras-hub) (2025.11.3)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from keras-hub) (0.3.13)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.12/dist-packages (from keras-hub) (2.19.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub->keras-hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub->keras-hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub->keras-hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-text->keras-hub) (2.19.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (2.19.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->keras-hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->keras-hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->keras-hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->keras-hub) (2026.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19.0->tensorflow-text->keras-hub) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall keras-nlp -y\n",
        "!pip install keras keras-hub --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BWLWM7jNq-J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BuessaG9Nq-J"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import os\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def backend(line, cell):\n",
        "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
        "    if current == required:\n",
        "        get_ipython().run_cell(cell)\n",
        "    else:\n",
        "        print(\n",
        "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
        "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc3670VgNq-J"
      },
      "source": [
        "## The mathematical building blocks of neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-fCEOSYNq-K"
      },
      "source": [
        "### A first look at a neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G83kIpfPNq-K"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HnxMJfINq-K"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o19ulGyLNq-K"
      },
      "outputs": [],
      "source": [
        "len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ5BcynONq-K"
      },
      "outputs": [],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEPjJH0nNq-L"
      },
      "outputs": [],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9OMrT4JNq-L"
      },
      "outputs": [],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgSR5rUsNq-L"
      },
      "outputs": [],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDx8R3M0Nq-L"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZqSp5gCNq-L"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7NF5izJNq-L"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ortvoJrrNq-L"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ExIeL5BNq-L"
      },
      "outputs": [],
      "source": [
        "test_digits = test_images[0:10]\n",
        "predictions = model.predict(test_digits)\n",
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1BRj6azNq-L"
      },
      "outputs": [],
      "source": [
        "predictions[0].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCQM68whNq-L"
      },
      "outputs": [],
      "source": [
        "predictions[0][7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R5eqJIjNq-L"
      },
      "outputs": [],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clLAiwmFNq-L"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"test_acc: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdkCFK-WNq-L"
      },
      "source": [
        "### Data representations for neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSW0-yiTNq-M"
      },
      "source": [
        "#### Scalars (rank-0 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5x80E6MNq-M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx26A84QNq-M"
      },
      "outputs": [],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-02V5NVNq-M"
      },
      "source": [
        "#### Vectors (rank-1 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFUDmAVxNq-M"
      },
      "outputs": [],
      "source": [
        "x = np.array([12, 3, 6, 14, 7])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ccMb9tpNq-M"
      },
      "outputs": [],
      "source": [
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJok_fX3Nq-M"
      },
      "source": [
        "#### Matrices (rank-2 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW7PjpkxNq-M"
      },
      "outputs": [],
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7pD2KojNq-M"
      },
      "source": [
        "#### Rank-3 tensors and higher-rank tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcBdrElmNq-M"
      },
      "outputs": [],
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "x.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oyUwXLYNq-M"
      },
      "source": [
        "#### Key attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdUpQ2eeNq-M"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XlC7ZTwNq-M"
      },
      "outputs": [],
      "source": [
        "train_images.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trkLzvviNq-M"
      },
      "outputs": [],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg7THk8bNq-M"
      },
      "outputs": [],
      "source": [
        "train_images.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy6vxhshNq-M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digit = train_images[4]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlfM8U0XNq-V"
      },
      "outputs": [],
      "source": [
        "train_labels[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URbKIO53Nq-V"
      },
      "source": [
        "#### Manipulating tensors in NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytPNGTkANq-V"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GgE3c84Nq-V"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100, :, :]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDZHvRReNq-V"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQk3p_upNq-V"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[:, 14:, 14:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwU5mY6dNq-W"
      },
      "outputs": [],
      "source": [
        "my_slice = train_images[:, 7:-7, 7:-7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE0HN8yjNq-W"
      },
      "source": [
        "#### The notion of data batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rc6gDvxNq-W"
      },
      "outputs": [],
      "source": [
        "batch = train_images[:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHTPBp-oNq-W"
      },
      "outputs": [],
      "source": [
        "batch = train_images[128:256]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnE8cwK8Nq-W"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "batch = train_images[128 * n : 128 * (n + 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zZ9fep1Nq-W"
      },
      "source": [
        "#### Real-world examples of data tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_QgIYihNq-W"
      },
      "source": [
        "##### Vector data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo1O093ONq-W"
      },
      "source": [
        "##### Timeseries data or sequence data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj0kctWfNq-W"
      },
      "source": [
        "##### Image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiXpAk7MNq-W"
      },
      "source": [
        "##### Video data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVyn1sFBNq-W"
      },
      "source": [
        "### The gears of neural networks: Tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9hm11NGNq-W"
      },
      "source": [
        "#### Element-wise operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCiYaM6XNq-W"
      },
      "outputs": [],
      "source": [
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo2xvJ_DNq-W"
      },
      "outputs": [],
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D60Oq-6pNq-W"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.0)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH-VdzNGNq-X"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-xllkcDNq-X"
      },
      "source": [
        "#### Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg_LJxXuNq-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.random.random((32, 10))\n",
        "y = np.random.random((10,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXiZil2Nq-X"
      },
      "outputs": [],
      "source": [
        "y = np.expand_dims(y, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jQCUh76Nq-X"
      },
      "outputs": [],
      "source": [
        "Y = np.tile(y, (32, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16Pje5VPNq-X"
      },
      "outputs": [],
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUXFTKY3Nq-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIR6bxW_Nq-X"
      },
      "source": [
        "#### Tensor product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJEQNvnXNq-X"
      },
      "outputs": [],
      "source": [
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "\n",
        "z = np.matmul(x, y)\n",
        "z = x @ y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgqGYMGzNq-X"
      },
      "outputs": [],
      "source": [
        "def naive_vector_product(x, y):\n",
        "    assert len(x.shape) == 1\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0.0\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcPEywu_Nq-X"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_product(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            z[i] += x[i, j] * y[j]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEreaTWRNq-X"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_product(x, y):\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        z[i] = naive_vector_product(x[i, :], y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9WWqVVDNq-X"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_product(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 2\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros((x.shape[0], y.shape[1]))\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(y.shape[1]):\n",
        "            row_x = x[i, :]\n",
        "            column_y = y[:, j]\n",
        "            z[i, j] = naive_vector_product(row_x, column_y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AlKPzfPNq-X"
      },
      "source": [
        "#### Tensor reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBKFhUaiNq-X"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3VuZ7WINq-Y"
      },
      "outputs": [],
      "source": [
        "x = np.array([[0., 1.],\n",
        "              [2., 3.],\n",
        "              [4., 5.]])\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ipg3SB7Nq-Y"
      },
      "outputs": [],
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKD2aU_QNq-Y"
      },
      "outputs": [],
      "source": [
        "x = x.reshape((2, 3))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8dhrK-HNq-Y"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-QVaJUBNq-Y"
      },
      "source": [
        "#### Geometric interpretation of tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gappHkJcNq-Y"
      },
      "source": [
        "#### A geometric interpretation of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8pw3rs2Nq-Y"
      },
      "source": [
        "### The engine of neural networks: Gradient-based optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQHcPaA-Nq-Y"
      },
      "source": [
        "#### What's a derivative?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p61URDJ9Nq-Y"
      },
      "source": [
        "#### Derivative of a tensor operation: The gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJncOnYMNq-Y"
      },
      "source": [
        "#### Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efsw2hjTNq-Y"
      },
      "source": [
        "#### Chaining derivatives: The Backpropagation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHACZ-gENq-Y"
      },
      "source": [
        "##### The chain rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naicGki5Nq-Y"
      },
      "source": [
        "##### Automatic differentiation with computation graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4K7b9wTNq-Y"
      },
      "source": [
        "### Looking back at our first example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RvYMJhgNq-Y"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yJ0nGDONq-Y"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I5y-Kw7Nq-Z"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFHqa41oNq-Z"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo7kY2v7Nq-Z"
      },
      "source": [
        "#### Reimplementing our first example from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgqlMAbaNq-Z"
      },
      "source": [
        "##### A simple Dense class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q_nrt7-Nq-Z"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import ops\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation=None):\n",
        "        self.activation = activation\n",
        "        self.W = keras.Variable(\n",
        "            shape=(input_size, output_size), initializer=\"uniform\"\n",
        "        )\n",
        "        self.b = keras.Variable(shape=(output_size,), initializer=\"zeros\")\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = ops.matmul(inputs, self.W)\n",
        "        x = x + self.b\n",
        "        if self.activation is not None:\n",
        "            x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHIGyxoxNq-Z"
      },
      "source": [
        "##### A simple Sequential class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtZj3xSkNq-Z"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        weights = []\n",
        "        for layer in self.layers:\n",
        "            weights += layer.weights\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdKAkeQuNq-Z"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential(\n",
        "    [\n",
        "        NaiveDense(input_size=28 * 28, output_size=512, activation=ops.relu),\n",
        "        NaiveDense(input_size=512, output_size=10, activation=ops.softmax),\n",
        "    ]\n",
        ")\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIKq2cB4Nq-Z"
      },
      "source": [
        "##### A batch generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k94mRrINq-Z"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yxXW_f6Nq-Z"
      },
      "source": [
        "#### Running one training step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sQG4s_PNq-Z"
      },
      "source": [
        "##### The weight update step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuZYWWmPNq-Z"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign(w - g * learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LrItM19Nq-Z"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACMe7E5YNq-a"
      },
      "source": [
        "##### Gradient computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZFkVehlNq-a"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.zeros(shape=())\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_px8jc6cNq-a"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        loss = ops.sparse_categorical_crossentropy(labels_batch, predictions)\n",
        "        average_loss = ops.mean(loss)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK5WIVQaNq-a"
      },
      "source": [
        "#### The full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQPzb-A7Nq-a"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DLeK-gGNq-a"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b9rWkIVNq-a"
      },
      "source": [
        "#### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqie1SBjNq-a"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "predictions = model(test_images)\n",
        "predicted_labels = ops.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "f\"accuracy: {ops.mean(matches):.2f}\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chapter02_mathematical-building-blocks",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}